{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5921dd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaven/anaconda3/envs/face_rec/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import string    \n",
    "import random \n",
    "import torchreid\n",
    "from glob import glob\n",
    "import os.path as osp\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dcea3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewDataset(torchreid.data.datasets.ImageDataset):\n",
    "    dataset_dir = 'data/custom_camera_data/'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.train_dir = self.dataset_dir + \"train\"  \n",
    "        self.query_dir = self.dataset_dir + \"train\"\n",
    "        self.gallery_dir = self.dataset_dir + \"train\"\n",
    "        \n",
    "        train = self.process_dir(self.train_dir, isQuery=False)\n",
    "        query = self.process_dir(self.query_dir, isQuery=True)\n",
    "        gallery = self.process_dir(self.gallery_dir, isQuery=False)\n",
    "\n",
    "        super(NewDataset, self).__init__(train, query, gallery, **kwargs)\n",
    "        \n",
    "    def process_dir(self, dir_path, isQuery):\n",
    "        img_paths = glob(osp.join(dir_path, '*.png'))\n",
    "        \n",
    "        data = []\n",
    "        for img_path in img_paths:\n",
    "            img_name = img_path.split('/')[-1]\n",
    "            name_splitted = img_name.split('_')\n",
    "            pid = int(name_splitted[0][1:])\n",
    "            camid = int(name_splitted[1][1:])\n",
    "\n",
    "            if isQuery:\n",
    "                camid += 10  # index starts from 0\n",
    "\n",
    "            data.append((img_path, pid, camid))\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b369b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 250x250\n",
      "+ random flip\n",
      "+ random crop (enlarge to 281x281 and crop 250x250)\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 250x250\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Loaded NewDataset\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |    15 |    12774 |         1\n",
      "  query    |    15 |    12774 |         1\n",
      "  gallery  |    15 |    12774 |         1\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded NewDataset\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |    15 |    12774 |         1\n",
      "  query    |    15 |    12774 |         1\n",
      "  gallery  |    15 |    12774 |         1\n",
      "  ----------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['OMCB0XN0ENO']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 15\n",
      "  # source images   : 12774\n",
      "  # source cameras  : 1\n",
      "  target            : ['OMCB0XN0ENO']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = ''.join(random.choices(string.ascii_uppercase + string.digits, k=random.randint(1, 25)))\n",
    "torchreid.data.register_image_dataset(dataset_name, NewDataset)\n",
    "\n",
    "datamanager = torchreid.data.ImageDataManager(\n",
    "    sources=dataset_name, \n",
    "    height=250, \n",
    "    width=250, \n",
    "    batch_size_train=32, \n",
    "    batch_size_test=100,\n",
    "    transforms=[\"random_flip\", \"random_crop\"],\n",
    "#     train_sampler='RandomIdentitySampler',  # RandomDatasetSampler RandomIdentitySampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb61248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"/home/zaven/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Successfully loaded pretrained weights from \"models/retrain_osnet_x1_0/model/lfw_model.pth.tar-90\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    }
   ],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name=\"osnet_x1_0\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"triplet\",\n",
    "    pretrained=True\n",
    ").to(device).train()\n",
    "\n",
    "weight_path = f\"models/retrain_osnet_x1_0/model/lfw_model.pth.tar-90\"\n",
    "torchreid.utils.load_pretrained_weights(model, weight_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061dd83a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Start training\n",
      "epoch: [1/100][99/399]\ttime 0.237 (0.229)\tdata 0.000 (0.009)\teta 2:31:35\tloss_t 0.0169 (0.0360)\tloss_x 0.7146 (0.8928)\tacc 96.8750 (98.9268)\tlr 0.003000\n",
      "epoch: [1/100][198/399]\ttime 0.240 (0.223)\tdata 0.001 (0.005)\teta 2:27:26\tloss_t 0.0000 (0.0222)\tloss_x 0.6190 (0.7747)\tacc 100.0000 (99.3845)\tlr 0.003000\n",
      "epoch: [1/100][297/399]\ttime 0.241 (0.222)\tdata 0.001 (0.003)\teta 2:26:37\tloss_t 0.0000 (0.0156)\tloss_x 0.6116 (0.7242)\tacc 100.0000 (99.5476)\tlr 0.003000\n",
      "epoch: [1/100][396/399]\ttime 0.224 (0.221)\tdata 0.000 (0.003)\teta 2:25:48\tloss_t 0.0689 (0.0128)\tloss_x 0.6759 (0.6975)\tacc 100.0000 (99.6528)\tlr 0.003000\n",
      "epoch: [2/100][99/399]\ttime 0.221 (0.228)\tdata 0.000 (0.009)\teta 2:29:43\tloss_t 0.0024 (0.0060)\tloss_x 0.5968 (0.6194)\tacc 100.0000 (99.8737)\tlr 0.003000\n",
      "epoch: [2/100][198/399]\ttime 0.207 (0.223)\tdata 0.001 (0.005)\teta 2:26:14\tloss_t 0.0000 (0.0038)\tloss_x 0.5959 (0.6122)\tacc 100.0000 (99.8895)\tlr 0.003000\n",
      "epoch: [2/100][297/399]\ttime 0.231 (0.222)\tdata 0.002 (0.004)\teta 2:25:08\tloss_t 0.0000 (0.0030)\tloss_x 0.5873 (0.6080)\tacc 100.0000 (99.9053)\tlr 0.003000\n",
      "epoch: [2/100][396/399]\ttime 0.202 (0.222)\tdata 0.000 (0.003)\teta 2:24:22\tloss_t 0.0000 (0.0023)\tloss_x 0.5968 (0.6054)\tacc 100.0000 (99.9290)\tlr 0.003000\n",
      "epoch: [3/100][99/399]\ttime 0.254 (0.252)\tdata 0.001 (0.010)\teta 2:44:05\tloss_t 0.0000 (0.0006)\tloss_x 0.5994 (0.6006)\tacc 100.0000 (99.9369)\tlr 0.003000\n",
      "epoch: [3/100][198/399]\ttime 0.189 (0.244)\tdata 0.001 (0.006)\teta 2:38:04\tloss_t 0.0000 (0.0007)\tloss_x 0.5954 (0.6003)\tacc 100.0000 (99.9527)\tlr 0.003000\n",
      "epoch: [3/100][297/399]\ttime 0.234 (0.237)\tdata 0.006 (0.004)\teta 2:33:19\tloss_t 0.0000 (0.0006)\tloss_x 0.5807 (0.5983)\tacc 100.0000 (99.9684)\tlr 0.003000\n",
      "epoch: [3/100][396/399]\ttime 0.223 (0.233)\tdata 0.001 (0.004)\teta 2:30:13\tloss_t 0.0140 (0.0006)\tloss_x 0.6022 (0.5974)\tacc 100.0000 (99.9763)\tlr 0.003000\n",
      "epoch: [4/100][99/399]\ttime 0.228 (0.239)\tdata 0.002 (0.010)\teta 2:33:49\tloss_t 0.0000 (0.0001)\tloss_x 0.5846 (0.5928)\tacc 100.0000 (99.9684)\tlr 0.003000\n",
      "epoch: [4/100][198/399]\ttime 0.202 (0.229)\tdata 0.001 (0.006)\teta 2:26:43\tloss_t 0.0000 (0.0001)\tloss_x 0.5962 (0.5912)\tacc 100.0000 (99.9369)\tlr 0.003000\n",
      "epoch: [4/100][297/399]\ttime 0.245 (0.225)\tdata 0.000 (0.004)\teta 2:24:20\tloss_t 0.0000 (0.0003)\tloss_x 0.6019 (0.5938)\tacc 100.0000 (99.9474)\tlr 0.003000\n",
      "epoch: [4/100][396/399]\ttime 0.210 (0.225)\tdata 0.000 (0.004)\teta 2:23:40\tloss_t 0.0000 (0.0005)\tloss_x 0.6198 (0.5948)\tacc 100.0000 (99.9605)\tlr 0.003000\n",
      "epoch: [5/100][99/399]\ttime 0.228 (0.228)\tdata 0.000 (0.010)\teta 2:25:28\tloss_t 0.0000 (0.0005)\tloss_x 0.5833 (0.5910)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [5/100][198/399]\ttime 0.212 (0.225)\tdata 0.001 (0.006)\teta 2:22:48\tloss_t 0.0000 (0.0007)\tloss_x 0.5879 (0.5917)\tacc 100.0000 (99.9684)\tlr 0.003000\n",
      "epoch: [5/100][297/399]\ttime 0.236 (0.223)\tdata 0.002 (0.004)\teta 2:21:08\tloss_t 0.0000 (0.0009)\tloss_x 0.6138 (0.5926)\tacc 100.0000 (99.9790)\tlr 0.003000\n",
      "epoch: [5/100][396/399]\ttime 0.204 (0.221)\tdata 0.000 (0.003)\teta 2:19:52\tloss_t 0.0000 (0.0007)\tloss_x 0.5872 (0.5923)\tacc 100.0000 (99.9763)\tlr 0.003000\n",
      "epoch: [6/100][99/399]\ttime 0.237 (0.230)\tdata 0.001 (0.009)\teta 2:24:51\tloss_t 0.0000 (0.0008)\tloss_x 0.5954 (0.5899)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [6/100][198/399]\ttime 0.232 (0.226)\tdata 0.001 (0.005)\teta 2:21:51\tloss_t 0.0000 (0.0004)\tloss_x 0.5752 (0.5889)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [6/100][297/399]\ttime 0.184 (0.224)\tdata 0.000 (0.004)\teta 2:20:29\tloss_t 0.0000 (0.0003)\tloss_x 0.5791 (0.5868)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [6/100][396/399]\ttime 0.216 (0.224)\tdata 0.000 (0.003)\teta 2:19:47\tloss_t 0.0000 (0.0002)\tloss_x 0.5922 (0.5863)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [7/100][99/399]\ttime 0.210 (0.226)\tdata 0.001 (0.009)\teta 2:20:48\tloss_t 0.0000 (0.0000)\tloss_x 0.5946 (0.5822)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [7/100][198/399]\ttime 0.229 (0.222)\tdata 0.000 (0.005)\teta 2:18:20\tloss_t 0.0000 (0.0000)\tloss_x 0.5857 (0.5810)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [7/100][297/399]\ttime 0.240 (0.220)\tdata 0.015 (0.004)\teta 2:16:32\tloss_t 0.0000 (0.0000)\tloss_x 0.5888 (0.5805)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [7/100][396/399]\ttime 0.202 (0.220)\tdata 0.000 (0.003)\teta 2:16:07\tloss_t 0.0000 (0.0000)\tloss_x 0.5737 (0.5803)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [8/100][99/399]\ttime 0.215 (0.227)\tdata 0.000 (0.011)\teta 2:19:54\tloss_t 0.0000 (0.0000)\tloss_x 0.5736 (0.5801)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [8/100][198/399]\ttime 0.221 (0.224)\tdata 0.000 (0.006)\teta 2:17:49\tloss_t 0.0000 (0.0000)\tloss_x 0.5908 (0.5796)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [8/100][297/399]\ttime 0.207 (0.222)\tdata 0.000 (0.004)\teta 2:16:14\tloss_t 0.0000 (0.0000)\tloss_x 0.5800 (0.5788)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [8/100][396/399]\ttime 0.192 (0.222)\tdata 0.000 (0.003)\teta 2:15:56\tloss_t 0.0000 (0.0000)\tloss_x 0.5755 (0.5785)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [9/100][99/399]\ttime 0.218 (0.235)\tdata 0.000 (0.010)\teta 2:23:16\tloss_t 0.0000 (0.0000)\tloss_x 0.5706 (0.5758)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [9/100][198/399]\ttime 0.229 (0.227)\tdata 0.001 (0.006)\teta 2:17:56\tloss_t 0.0000 (0.0000)\tloss_x 0.5862 (0.5762)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [9/100][297/399]\ttime 0.258 (0.225)\tdata 0.001 (0.004)\teta 2:16:15\tloss_t 0.0000 (0.0000)\tloss_x 0.5826 (0.5762)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [9/100][396/399]\ttime 0.208 (0.223)\tdata 0.000 (0.004)\teta 2:14:45\tloss_t 0.0000 (0.0000)\tloss_x 0.5765 (0.5758)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [10/100][99/399]\ttime 0.219 (0.227)\tdata 0.001 (0.010)\teta 2:17:15\tloss_t 0.0000 (0.0000)\tloss_x 0.5737 (0.5740)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [10/100][198/399]\ttime 0.222 (0.226)\tdata 0.000 (0.006)\teta 2:16:11\tloss_t 0.0000 (0.0000)\tloss_x 0.5690 (0.5738)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [10/100][297/399]\ttime 0.240 (0.225)\tdata 0.001 (0.004)\teta 2:14:57\tloss_t 0.0000 (0.0000)\tloss_x 0.5801 (0.5741)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [10/100][396/399]\ttime 0.223 (0.225)\tdata 0.000 (0.003)\teta 2:14:23\tloss_t 0.0000 (0.0000)\tloss_x 0.5676 (0.5738)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "##### Evaluating OMCB0XN0ENO (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 12774-by-512 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 12774-by-512 matrix\n",
      "Speed: 0.0593 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 100.0%\n",
      "CMC curve\n",
      "Rank-1  : 100.0%\n",
      "Rank-5  : 100.0%\n",
      "Rank-10 : 100.0%\n",
      "Rank-20 : 100.0%\n",
      "Checkpoint saved to \"models/retrain_osnet_x1_0/model/model.pth.tar-10\"\n",
      "epoch: [11/100][99/399]\ttime 0.218 (0.243)\tdata 0.000 (0.013)\teta 2:25:00\tloss_t 0.0000 (0.0000)\tloss_x 0.5633 (0.5704)\tacc 100.0000 (100.0000)\tlr 0.003000\n",
      "epoch: [11/100][198/399]\ttime 0.208 (0.231)\tdata 0.001 (0.007)\teta 2:17:19\tloss_t 0.0000 (0.0000)\tloss_x 0.5691 (0.5716)\tacc 100.0000 (100.0000)\tlr 0.003000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_538849/3318430684.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0meval_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtest_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/face_rec/lib/python3.7/site-packages/torchreid/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, save_dir, max_epoch, start_epoch, print_freq, fixbase_epoch, open_layers, start_eval, eval_freq, test_only, dist_metric, normalize_feature, visrank, visrank_topk, use_metric_cuhk03, ranks, rerank)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mfixbase_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixbase_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mopen_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             )\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/face_rec/lib/python3.7/site-packages/torchreid/engine/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, print_freq, fixbase_epoch, open_layers)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mloss_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0mbatch_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/face_rec/lib/python3.7/site-packages/torchreid/engine/image/triplet.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/face_rec/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/face_rec/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim_name = 'adam'  # adam sgd radam\n",
    "lr = 0.003  # 0.0005 0.0003 0.0001  # DO NOT SET lr MORE THAN 0.01, IT'S CRUSHING FOR FACE, START FROM lr = 0.003 \n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim=optim_name,\n",
    "    lr=lr, \n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler=\"single_step\", \n",
    "    stepsize=20,\n",
    ")\n",
    "\n",
    "engine = torchreid.engine.ImageTripletEngine(\n",
    "    datamanager,\n",
    "    model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    margin=0.3,  # by default 0.3\n",
    "    weight_t=50,  # weight for triplet loss\n",
    "    weight_x=1, # weight for softmax loss\n",
    ")\n",
    "\n",
    "engine.run(\n",
    "    save_dir=\"models/retrain_osnet_x1_0\",\n",
    "    max_epoch=100, \n",
    "    eval_freq=10, \n",
    "    print_freq=99,\n",
    "    test_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1a0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
